{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inferencia con Modelos Paramétricos y No Paramétricos\n",
    "\n",
    "Modelar es un paso clave en el proceso de la inferencia estadística. En esta secuencia de aprendizaje veremos como ajustar modelos paramétricos y no paramétricos a nuestros datos\n",
    "\n",
    "- En el caso de modelamiento paramétrico nos enfocaremos en métodos frecuentistas: Estimación de máxima verosimilitud (MLE)\n",
    "- Luego revisaremos técnicas de modelamiento no paramétrico: Histogramas y Estimación de densidad por kernels (KDE)\n",
    "- Después de esto volveremos al caso paramétrico y extenderemos MLE utilizando priors: Estimación de Máximo a Posteriori (MAP)\n",
    "- Finalmente presentaremos algunas ideas de modelamiento bayesiano, las cuales serán desarrolladas en profundidad al final de este curso\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Qué es inferencia estadística?\n",
    "\n",
    "Inferencia, en general, es \n",
    "\n",
    "> Extraer conclusiones a partir de los hechos a través de una premisa científica\n",
    "\n",
    "Y en el caso de particular de **inferencia estadística** tenemos\n",
    "\n",
    "- Hechos: Una muestra de los datos (o datos observados)\n",
    "- Premisa: Modelo probabilístico (e.g., distribución Gaussiana)\n",
    "- Conclusión: Propiedades de una población (i.e., una distribución de probabilidad subyacente de los datos)\n",
    "\n",
    "Es decir, inferencia estadística es extraer conclusiones de las propiedades de una población a través de una muestra de esta población.\n",
    "\n",
    "Los siguientes son ejemplos de tareas típicas de inferencias estadística:\n",
    "\n",
    "- **Estimación de parámetros**: ¿Cuál es el mejor estimado del parámetro de un modelo dado en base a los datos observados?\n",
    "- **Estimación de confianza:** ¿Qué tan confiable es nuestro estimador puntual de dicho parámetro?  \n",
    "- **Test de hiṕotesis:** ¿Son los datos consistentes con una hipótesis en particular? \n",
    "\n",
    "Veamos la primera tarea en este capítulo, y veamos las otras en el capítulo Pensamiento Estadístico."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Diferencias entre métodos paramétricos y no-paramétricos\n",
    "\n",
    "En estadística se hace la distinción entre métodos parámetricos y no paramétricos. Los primeros son métodos que **hacen supuestos sobre la distribución de probabilidad subyacente de los datos**, por ejemplo \n",
    "\n",
    "> \"La población tiene una distribución normal\"\n",
    "\n",
    "Los segundos en cambio no suponen una forma teórica específica para las distribuciones subyancentes, sin embargo si suelen hacer otros supuestos \"menos fuertes\", por ejemplo\n",
    "\n",
    "> \"La distribución subyacente es continua\" o \"las observaciones son independientes e idénticamente distribuidos\"\n",
    "\n",
    "Los métodos no parámetricos son entonces menos restrictivos pero suelen ser menos sencibles (menor potencia estadística) que sus contrapartes paramétricas\n",
    "\n",
    "En el caso específico del modelamiento también se puede hacer la distinción anterior:\n",
    "\n",
    "**Modelos paramétricos:** \n",
    "\n",
    "- Características claves: \n",
    "    - Hacen supuestos sobre la distribución de probabilidad de los datos (En el caso bayesiano también se supone una distribución para los parámetros del modelo). \n",
    "    - El modelo tiene una estructura fija, es decir un número fijo de parámetros\n",
    "- Pros: En general, son más simples de ajustar (requieren menos datos, son más rapidos para entrenar), y más simples de interpretar\n",
    "- Cons: En general, son menos flexibles y no tan adecuados para problemas complejos\n",
    "- Ejemplo: Modelo gaussiano único, modelo de mezcla de Gaussianas, regresión lineal\n",
    "\n",
    "**Modelos no-paramétricos:** \n",
    "\n",
    "- Características claves:\n",
    "    - No hacen supuestos basados en distribuciones específicas (pero si en propiedades de dicha distribución)  \n",
    "    - El número de parámetros puede depender de la cantidad de datos de entrenamiento (o ser infinito)\n",
    "- Pros: En general, son más flexibles y más adecuados para problemas complejos\n",
    "- Cons: En general, son más difíciles de ajustar (requieren más datos, más lentos para entrenar), más difíciles de interpretar, y tienen más riesgo de sobreajuste\n",
    "- Ejemplo: Histograma, árbol de decisión, k vecinos más próximos\n",
    "\n",
    ":::{warning}\n",
    "\n",
    "*No-paramétrico* no significa no hay parámetros; en cambio, significa que no hay un número fijo de parámetros incluso puede ser infinitos!\n",
    "\n",
    ":::   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## La diferencia entre inferencia frecuentista y bayesiana\n",
    "\n",
    "En general, se reconocen dos paradigmas o perspectivas en inferencia estadística: Frecuentista (F) y Bayesiana (B). Existen diferencias conceptuales importantes entre ellas, por ejemplo\n",
    "\n",
    "**Definición de probabilidad:**\n",
    "\n",
    "- F: Probabilidad es la frecuencia relativa de un evento. Es una propiedad objetiva \n",
    "- B: Probabilidad es el grado de credibilidad de un evento. Es una propiedad subjetiva\n",
    "\n",
    "**Parámetros:**\n",
    "\n",
    "- F: Los parámetros son variables determínistas, es decir que su valor es puntual\n",
    "- B: Los parámetros son variables aleatorias, es decir que tienen distribuciones asociadas que cuantifican su incertidumbre. Podemos calcular valores esperados para nuestros parámetros\n",
    "\n",
    "Los conceptos de métodos paramétricos y no-paramétricos son diferentes que los conceptos de inferencia frecuentista y bayesiana. Podemos tener 4 tipos de métodos que provienen de las combinación de ellos.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-book-info337",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, May 15 2023, 18:51:40) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "671065b571a5fdb465b5ce5eb6a0c42c0bf0a3bd98adc4932f551a92e7f95554"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
